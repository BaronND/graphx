<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>GraphX by amplab</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>GraphX</h1>
        <p>Unifying Graphs and Tables</p>

        <p class="view"><a href="https://github.com/amplab/graphx">View the Project on GitHub <small>amplab/graphx</small></a></p>


        <ul>
          <li><a href="https://github.com/amplab/graphx/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/amplab/graphx/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/amplab/graphx">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <h1>
<a name="graphx-unifying-graphs-and-tables" class="anchor" href="#graphx-unifying-graphs-and-tables"><span class="octicon octicon-link"></span></a>GraphX: Unifying Graphs and Tables</h1>

<p>GraphX extends the distributed fault-tolerant collections API and
interactive console of <a href="http://spark.incubator.apache.org">Spark</a> with
a new graph API which leverages recent advances in graph systems
(e.g., <a href="http://graphlab.org">GraphLab</a>) to enable users to easily and
interactively build, transform, and reason about graph structured data
at scale.</p>

<h2>
<a name="motivation" class="anchor" href="#motivation"><span class="octicon octicon-link"></span></a>Motivation</h2>

<p>From social networks and targeted advertising to protein modeling and
astrophysics, big graphs capture the structure in data and are central
to the recent advances in machine learning and data mining. Directly
applying existing <em>data-parallel</em> tools (e.g.,
<a href="http://hadoop.apache.org">Hadoop</a> and
<a href="http://spark.incubator.apache.org">Spark</a>) to graph computation tasks
can be cumbersome and inefficient.  The need for intuitive, scalable
tools for graph computation has lead to the development of new
<em>graph-parallel</em> systems (e.g.,
<a href="http://http://giraph.apache.org">Pregel</a> and
<a href="http://graphlab.org">GraphLab</a>) which are designed to efficiently
execute graph algorithms.  Unfortunately, these systems do not address
the challenges of graph construction and transformation and provide
limited fault-tolerance and support for interactive analysis.</p>

<p align="center">
  <img src="https://raw.github.com/jegonzal/graphx/Documentation/docs/img/data_parallel_vs_graph_parallel.png"></p>

<h2>
<a name="solution" class="anchor" href="#solution"><span class="octicon octicon-link"></span></a>Solution</h2>

<p>The GraphX project combines the advantages of both data-parallel and
graph-parallel systems by efficiently expressing graph computation
within the <a href="http://spark.incubator.apache.org">Spark</a> framework.  We
leverage new ideas in distributed graph representation to efficiently
distribute graphs as tabular data-structures.  Similarly, we leverage
advances in data-flow systems to exploit in-memory computation and
fault-tolerance.  We provide powerful new operations to simplify graph
construction and transformation.  Using these primitives we implement
the PowerGraph and Pregel abstractions in less than 20 lines of code.
Finally, by exploiting the Scala foundation of Spark, we enable users
to interactively load, transform, and compute on massive graphs.</p>

<p align="center">
  <img src="https://raw.github.com/jegonzal/graphx/Documentation/docs/img/tables_and_graphs.png"></p>

<h2>
<a name="examples" class="anchor" href="#examples"><span class="octicon octicon-link"></span></a>Examples</h2>

<p>Suppose I want to build a graph from some text files, restrict the graph 
to important relationships and users, run page-rank on the sub-graph, and
then finally return attributes associated with the top users.  I can do 
all of this in just a few lines with GraphX:</p>

<div class="highlight highlight-scala"><pre><span class="c1">// Connect to the Spark cluster</span>
<span class="k">val</span> <span class="n">sc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkContext</span><span class="o">(</span><span class="s">"spark://master.amplab.org"</span><span class="o">,</span> <span class="s">"research"</span><span class="o">)</span>

<span class="c1">// Load my user data and prase into tuples of user id and attribute list</span>
<span class="k">val</span> <span class="n">users</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">"hdfs://user_attributes.tsv"</span><span class="o">)</span>
  <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">).</span><span class="n">map</span><span class="o">(</span> <span class="n">parts</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">parts</span><span class="o">.</span><span class="n">head</span><span class="o">,</span> <span class="n">parts</span><span class="o">.</span><span class="n">tail</span><span class="o">)</span> <span class="o">)</span>

<span class="c1">// Parse the edge data which is already in userId -&gt; userId format</span>
<span class="k">val</span> <span class="n">followerGraph</span> <span class="k">=</span> <span class="nc">Graph</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="s">"hdfs://followers.tsv"</span><span class="o">)</span>

<span class="c1">// Attach the user attributes</span>
<span class="k">val</span> <span class="n">graph</span> <span class="k">=</span> <span class="n">followerGraph</span><span class="o">.</span><span class="n">outerJoinVertices</span><span class="o">(</span><span class="n">users</span><span class="o">){</span> 
  <span class="k">case</span> <span class="o">(</span><span class="n">uid</span><span class="o">,</span> <span class="n">deg</span><span class="o">,</span> <span class="nc">Some</span><span class="o">(</span><span class="n">attrList</span><span class="o">))</span> <span class="k">=&gt;</span> <span class="n">attrList</span>
  <span class="c1">// Some users may not have attributes so we set them as empty</span>
  <span class="k">case</span> <span class="o">(</span><span class="n">uid</span><span class="o">,</span> <span class="n">deg</span><span class="o">,</span> <span class="nc">None</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="nc">Array</span><span class="o">.</span><span class="n">empty</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> 
  <span class="o">}</span>

<span class="c1">// Restrict the graph to users which have exactly two attributes</span>
<span class="k">val</span> <span class="n">subgraph</span> <span class="k">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">subgraph</span><span class="o">((</span><span class="n">vid</span><span class="o">,</span> <span class="n">attr</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">attr</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">2</span><span class="o">)</span>

<span class="c1">// Compute the PageRank </span>
<span class="k">val</span> <span class="n">pagerankGraph</span> <span class="k">=</span> <span class="nc">Analytics</span><span class="o">.</span><span class="n">pagerank</span><span class="o">(</span><span class="n">subgraph</span><span class="o">)</span>

<span class="c1">// Get the attributes of the top pagerank users</span>
<span class="k">val</span> <span class="n">userInfoWithPageRank</span> <span class="k">=</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">outerJoinVertices</span><span class="o">(</span><span class="n">pagerankGraph</span><span class="o">.</span><span class="n">vertices</span><span class="o">){</span>
  <span class="k">case</span> <span class="o">(</span><span class="n">uid</span><span class="o">,</span> <span class="n">attrList</span><span class="o">,</span> <span class="nc">Some</span><span class="o">(</span><span class="n">pr</span><span class="o">))</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">pr</span><span class="o">,</span> <span class="n">attrList</span><span class="o">)</span>
  <span class="k">case</span> <span class="o">(</span><span class="n">uid</span><span class="o">,</span> <span class="n">attrList</span><span class="o">,</span> <span class="nc">None</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">pr</span><span class="o">,</span> <span class="n">attrList</span><span class="o">)</span>
  <span class="o">}</span>

<span class="n">println</span><span class="o">(</span><span class="n">userInfoWithPageRank</span><span class="o">.</span><span class="n">top</span><span class="o">(</span><span class="mi">5</span><span class="o">))</span>

</pre></div>

<h2>
<a name="online-documentation" class="anchor" href="#online-documentation"><span class="octicon octicon-link"></span></a>Online Documentation</h2>

<p>You can find the latest Spark documentation, including a programming
guide, on the project webpage at
<a href="http://spark.incubator.apache.org/documentation.html">http://spark.incubator.apache.org/documentation.html</a>.  This README
file only contains basic setup instructions.</p>

<h2>
<a name="building" class="anchor" href="#building"><span class="octicon octicon-link"></span></a>Building</h2>

<p>Spark requires Scala 2.9.3 (Scala 2.10 is not yet supported). The
project is built using Simple Build Tool (SBT), which is packaged with
it. To build Spark and its example programs, run:</p>

<pre><code>sbt/sbt assembly
</code></pre>

<p>Once you've built Spark, the easiest way to start using it is the
shell:</p>

<pre><code>./spark-shell
</code></pre>

<p>Or, for the Python API, the Python shell (<code>./pyspark</code>).</p>

<p>Spark also comes with several sample programs in the <code>examples</code>
directory.  To run one of them, use <code>./run-example &lt;class&gt;
&lt;params&gt;</code>. For example:</p>

<pre><code>./run-example org.apache.spark.examples.SparkLR local[2]
</code></pre>

<p>will run the Logistic Regression example locally on 2 CPUs.</p>

<p>Each of the example programs prints usage help if no params are given.</p>

<p>All of the Spark samples take a <code>&lt;master&gt;</code> parameter that is the
cluster URL to connect to. This can be a mesos:// or spark:// URL, or
"local" to run locally with one thread, or "local[N]" to run locally
with N threads.</p>

<h2>
<a name="a-note-about-hadoop-versions" class="anchor" href="#a-note-about-hadoop-versions"><span class="octicon octicon-link"></span></a>A Note About Hadoop Versions</h2>

<p>Spark uses the Hadoop core library to talk to HDFS and other
Hadoop-supported storage systems. Because the protocols have changed
in different versions of Hadoop, you must build Spark against the same
version that your cluster runs.  You can change the version by setting
the <code>SPARK_HADOOP_VERSION</code> environment when building Spark.</p>

<p>For Apache Hadoop versions 1.x, Cloudera CDH MRv1, and other Hadoop
versions without YARN, use:</p>

<pre><code># Apache Hadoop 1.2.1
$ SPARK_HADOOP_VERSION=1.2.1 sbt/sbt assembly

# Cloudera CDH 4.2.0 with MapReduce v1
$ SPARK_HADOOP_VERSION=2.0.0-mr1-cdh4.2.0 sbt/sbt assembly
</code></pre>

<p>For Apache Hadoop 2.x, 0.23.x, Cloudera CDH MRv2, and other Hadoop versions
with YARN, also set <code>SPARK_YARN=true</code>:</p>

<pre><code># Apache Hadoop 2.0.5-alpha
$ SPARK_HADOOP_VERSION=2.0.5-alpha SPARK_YARN=true sbt/sbt assembly

# Cloudera CDH 4.2.0 with MapReduce v2
$ SPARK_HADOOP_VERSION=2.0.0-cdh4.2.0 SPARK_YARN=true sbt/sbt assembly
</code></pre>

<p>For convenience, these variables may also be set through the
<code>conf/spark-env.sh</code> file described below.</p>

<p>When developing a Spark application, specify the Hadoop version by
adding the "hadoop-client" artifact to your project's
dependencies. For example, if you're using Hadoop 1.0.1 and build your
application using SBT, add this entry to <code>libraryDependencies</code>:</p>

<pre><code>"org.apache.hadoop" % "hadoop-client" % "1.2.1"
</code></pre>

<p>If your project is built with Maven, add this to your POM file's
<code>&lt;dependencies&gt;</code> section:</p>

<pre><code>&lt;dependency&gt;
  &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
  &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;
  &lt;version&gt;1.2.1&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>

<h2>
<a name="configuration" class="anchor" href="#configuration"><span class="octicon octicon-link"></span></a>Configuration</h2>

<p>Please refer to the <a href="http://spark.incubator.apache.org/docs/latest/configuration.html">Configuration
guide</a>
in the online documentation for an overview on how to configure Spark.</p>

<h2>
<a name="contributing-to-graphx" class="anchor" href="#contributing-to-graphx"><span class="octicon octicon-link"></span></a>Contributing to GraphX</h2>

<p>Contributions via GitHub pull requests are gladly accepted from their
original author. Along with any pull requests, please state that the
contribution is your original work and that you license the work to
the project under the project's open source license. Whether or not
you state this explicitly, by submitting any copyrighted material via
pull request, email, or other means you agree to license the material
under the project's open source license and warrant that you have the
legal authority to do so.</p>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/amplab">amplab</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>